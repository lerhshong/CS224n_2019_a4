{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from docopt import docopt\n",
    "from typing import List, Tuple, Dict, Set, Union\n",
    "from tqdm import tqdm\n",
    "from utils import read_corpus, batch_iter\n",
    "from vocab import Vocab, VocabEntry\n",
    "\n",
    "from nmt_model import NMT\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils\n",
    "\n",
    "#----------\n",
    "# CONSTANTS\n",
    "#----------\n",
    "BATCH_SIZE = 5\n",
    "EMBED_SIZE = 3\n",
    "HIDDEN_SIZE = 3\n",
    "DROPOUT_RATE = 0.0\n",
    "\n",
    "def reinitialize_layers(model):\n",
    "    \"\"\" Reinitialize the Layer Weights for Sanity Checks.\n",
    "    \"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(0.3)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.1)\n",
    "        elif type(m) == nn.Embedding:\n",
    "            m.weight.data.fill_(0.15)\n",
    "        elif type(m) == nn.Dropout:\n",
    "            nn.Dropout(DROPOUT_RATE)\n",
    "    with torch.no_grad():\n",
    "        model.apply(init_weights)\n",
    "\n",
    "\n",
    "def generate_outputs(model, source, target, vocab):\n",
    "    \"\"\" Generate outputs.\n",
    "    \"\"\"\n",
    "    print (\"-\"*80)\n",
    "    print(\"Generating Comparison Outputs\")\n",
    "    reinitialize_layers(model)\n",
    "\n",
    "    # Compute sentence lengths\n",
    "    source_lengths = [len(s) for s in source]\n",
    "\n",
    "    # Convert list of lists into tensors\n",
    "    source_padded = model.vocab.src.to_input_tensor(source, device=model.device)\n",
    "    target_padded = model.vocab.tgt.to_input_tensor(target, device=model.device)\n",
    "\n",
    "    # Run the model forward\n",
    "    with torch.no_grad():\n",
    "        enc_hiddens, dec_init_state = model.encode(source_padded, source_lengths)\n",
    "        enc_masks = model.generate_sent_masks(enc_hiddens, source_lengths)\n",
    "        combined_outputs = model.decode(enc_hiddens, enc_masks, dec_init_state, target_padded)\n",
    "\n",
    "    # Save Tensors to disk\n",
    "    torch.save(enc_hiddens, './sanity_check_en_es_data/enc_hiddens.pkl')\n",
    "    torch.save(dec_init_state, './sanity_check_en_es_data/dec_init_state.pkl') \n",
    "    torch.save(enc_masks, './sanity_check_en_es_data/enc_masks.pkl')\n",
    "    torch.save(combined_outputs, './sanity_check_en_es_data/combined_outputs.pkl')\n",
    "\n",
    "\n",
    "def question_1d_sanity_check(model, src_sents, tgt_sents, vocab):\n",
    "    \"\"\" Sanity check for question 1d. \n",
    "        Compares student output to that of model with dummy data.\n",
    "    \"\"\"\n",
    "    print(\"Running Sanity Check for Question 1d: Encode\")\n",
    "    print (\"-\"*80)\n",
    "\n",
    "    # Configure for Testing\n",
    "    reinitialize_layers(model)\n",
    "    source_lengths = [len(s) for s in src_sents]\n",
    "    source_padded = model.vocab.src.to_input_tensor(src_sents, device=model.device)\n",
    "\n",
    "    # Load Outputs\n",
    "    enc_hiddens_target = torch.load('./sanity_check_en_es_data/enc_hiddens.pkl')\n",
    "    dec_init_state_target = torch.load('./sanity_check_en_es_data/dec_init_state.pkl')\n",
    "\n",
    "    # Test\n",
    "    with torch.no_grad():\n",
    "        enc_hiddens_pred, dec_init_state_pred = model.encode(source_padded, source_lengths)\n",
    "    assert(np.allclose(enc_hiddens_target.numpy(), enc_hiddens_pred.numpy())), \"enc_hiddens is incorrect: it should be:\\n {} but is:\\n{}\".format(enc_hiddens_target, enc_hiddens_pred)\n",
    "    print(\"enc_hiddens Sanity Checks Passed!\")\n",
    "    assert(np.allclose(dec_init_state_target[0].numpy(), dec_init_state_pred[0].numpy())), \"dec_init_state[0] is incorrect: it should be:\\n {} but is:\\n{}\".format(dec_init_state_target[0], dec_init_state_pred[0])\n",
    "    print(\"dec_init_state[0] Sanity Checks Passed!\")\n",
    "    assert(np.allclose(dec_init_state_target[1].numpy(), dec_init_state_pred[1].numpy())), \"dec_init_state[1] is incorrect: it should be:\\n {} but is:\\n{}\".format(dec_init_state_target[1], dec_init_state_pred[1])\n",
    "    print(\"dec_init_state[1] Sanity Checks Passed!\")\n",
    "    print (\"-\"*80)\n",
    "    print(\"All Sanity Checks Passed for Question 1d: Encode!\")\n",
    "    print (\"-\"*80)\n",
    "\n",
    "\n",
    "def question_1e_sanity_check(model, src_sents, tgt_sents, vocab):\n",
    "    \"\"\" Sanity check for question 1e. \n",
    "        Compares student output to that of model with dummy data.\n",
    "    \"\"\"\n",
    "    print (\"-\"*80)\n",
    "    print(\"Running Sanity Check for Question 1e: Decode\")\n",
    "    print (\"-\"*80)\n",
    "\n",
    "    # Load Inputs\n",
    "    dec_init_state = torch.load('./sanity_check_en_es_data/dec_init_state.pkl')\n",
    "    enc_hiddens = torch.load('./sanity_check_en_es_data/enc_hiddens.pkl')\n",
    "    enc_masks = torch.load('./sanity_check_en_es_data/enc_masks.pkl')\n",
    "    target_padded = torch.load('./sanity_check_en_es_data/target_padded.pkl')\n",
    "\n",
    "    # Load Outputs\n",
    "    combined_outputs_target = torch.load('./sanity_check_en_es_data/combined_outputs.pkl')\n",
    "\n",
    "    # Configure for Testing\n",
    "    reinitialize_layers(model)\n",
    "    COUNTER = [0]\n",
    "    def stepFunction(Ybar_t, dec_state, enc_hiddens, enc_hiddens_proj, enc_masks):\n",
    "       dec_state = torch.load('./sanity_check_en_es_data/step_dec_state_{}.pkl'.format(COUNTER[0]))\n",
    "       o_t = torch.load('./sanity_check_en_es_data/step_o_t_{}.pkl'.format(COUNTER[0]))\n",
    "       COUNTER[0]+=1\n",
    "       return dec_state, o_t, None\n",
    "    model.step = stepFunction\n",
    "\n",
    "    # Run Tests\n",
    "    with torch.no_grad():\n",
    "        combined_outputs_pred = model.decode(enc_hiddens, enc_masks, dec_init_state, target_padded)\n",
    "    assert(np.allclose(combined_outputs_pred.numpy(), combined_outputs_target.numpy())), \"combined_outputs is incorrect: it should be:\\n {} but is:\\n{}\".format(combined_outputs_target, combined_outputs_pred)\n",
    "    print(\"combined_outputs Sanity Checks Passed!\")\n",
    "    print (\"-\"*80)\n",
    "    print(\"All Sanity Checks Passed for Question 1e: Decode!\")\n",
    "    print (\"-\"*80)\n",
    "\n",
    "def question_1f_sanity_check(model, src_sents, tgt_sents, vocab):\n",
    "    \"\"\" Sanity check for question 1f. \n",
    "        Compares student output to that of model with dummy data.\n",
    "    \"\"\"\n",
    "    print (\"-\"*80)\n",
    "    print(\"Running Sanity Check for Question 1f: Step\")\n",
    "    print (\"-\"*80)\n",
    "    reinitialize_layers(model)\n",
    "\n",
    "    # Inputs\n",
    "    Ybar_t = torch.load('./sanity_check_en_es_data/Ybar_t.pkl')\n",
    "    dec_init_state = torch.load('./sanity_check_en_es_data/dec_init_state.pkl')\n",
    "    enc_hiddens = torch.load('./sanity_check_en_es_data/enc_hiddens.pkl')\n",
    "    enc_masks = torch.load('./sanity_check_en_es_data/enc_masks.pkl')\n",
    "    enc_hiddens_proj = torch.load('./sanity_check_en_es_data/enc_hiddens_proj.pkl')\n",
    "\n",
    "    # Output\n",
    "    dec_state_target = torch.load('./sanity_check_en_es_data/dec_state.pkl')\n",
    "    o_t_target = torch.load('./sanity_check_en_es_data/o_t.pkl')\n",
    "    e_t_target = torch.load('./sanity_check_en_es_data/e_t.pkl')\n",
    "\n",
    "    # Run Tests\n",
    "    with torch.no_grad():\n",
    "        dec_state_pred, o_t_pred, e_t_pred= model.step(Ybar_t, dec_init_state, enc_hiddens, enc_hiddens_proj, enc_masks)\n",
    "    assert(np.allclose(dec_state_target[0].numpy(), dec_state_pred[0].numpy())), \"decoder_state[0] is incorrect: it should be:\\n {} but is:\\n{}\".format(dec_state_target[0], dec_state_pred[0])\n",
    "    print(\"dec_state[0] Sanity Checks Passed!\")\n",
    "    assert(np.allclose(dec_state_target[1].numpy(), dec_state_pred[1].numpy())), \"decoder_state[1] is incorrect: it should be:\\n {} but is:\\n{}\".format(dec_state_target[1], dec_state_pred[1])\n",
    "    print(\"dec_state[1] Sanity Checks Passed!\")\n",
    "    assert(np.allclose(o_t_target.numpy(), o_t_pred.numpy())), \"combined_output is incorrect: it should be:\\n {} but is:\\n{}\".format(o_t_target, o_t_pred)\n",
    "    print(\"combined_output  Sanity Checks Passed!\")\n",
    "    assert(np.allclose(e_t_target.numpy(), e_t_pred.numpy())), \"e_t is incorrect: it should be:\\n {} but is:\\n{}\".format(e_t_target, e_t_pred)\n",
    "    print(\"e_t Sanity Checks Passed!\")\n",
    "    print (\"-\"*80)    \n",
    "    print(\"All Sanity Checks Passed for Question 1f: Step!\")\n",
    "    print (\"-\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed * 13 // 7)\n",
    "\n",
    "# Load training data & vocabulary\n",
    "train_data_src = read_corpus('./sanity_check_en_es_data/train_sanity_check.es', 'src')\n",
    "train_data_tgt = read_corpus('./sanity_check_en_es_data/train_sanity_check.en', 'tgt')\n",
    "train_data = list(zip(train_data_src, train_data_tgt))\n",
    "\n",
    "for src_sents, tgt_sents in batch_iter(train_data, batch_size=BATCH_SIZE, shuffle=True):\n",
    "    src_sents = src_sents\n",
    "    tgt_sents = tgt_sents\n",
    "    break\n",
    "vocab = Vocab.load('./sanity_check_en_es_data/vocab_sanity_check.json') \n",
    "\n",
    "# Create NMT Model\n",
    "model = NMT(\n",
    "    embed_size=EMBED_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
